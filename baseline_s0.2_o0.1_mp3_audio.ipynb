{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! find . -name \".DS_Store\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_X_test_0 = len(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Test_0\"))\n",
    "n_X_test_1 = len(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Test_1\"))\n",
    "\n",
    "print(f\"X_test_0 has {n_X_test_0} batches.\")\n",
    "print(f\"X_test_1 has {n_X_test_1} batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X_test\n",
    "\n",
    "# set the amount of batches you wish to consider\n",
    "n = 10\n",
    "\n",
    "k = 1\n",
    "first = os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Test_0\")[0]\n",
    "X_test_0 = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Test_0/\" + first)\n",
    "\n",
    "for item in os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Test_0\")[1:]:\n",
    "    arr = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Test_0/\" + item)\n",
    "    X_test_0 = np.concatenate((X_test_0, arr), axis = 0)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "        break\n",
    "\n",
    "k = 1\n",
    "item = os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Test_1\")[0]\n",
    "X_test_1 = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Test_1/\" + item)\n",
    "\n",
    "for item in os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Test_1\")[1:]:\n",
    "    arr = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Test_1/\" + item)\n",
    "    X_test_1 = np.concatenate((X_test_1, arr), axis = 0)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "        break\n",
    "    \n",
    "X_test = np.concatenate((X_test_0, X_test_1), axis = 0)\n",
    "\n",
    "# load y_test\n",
    "\n",
    "y_test = np.loadtxt(\"labels/seconds_0.2_overlap_0.1/labels_Test.txt\")\n",
    "\n",
    "# split\n",
    "\n",
    "y_test_0 = y_test[y_test == 0]\n",
    "y_test_1 = y_test[y_test == 1]\n",
    "\n",
    "# truncate according to the number of slices above\n",
    "\n",
    "y_test_0 = y_test_0[0: X_test_0.shape[0]]\n",
    "y_test_1 = y_test_1[0: X_test_1.shape[0]]\n",
    "\n",
    "# concatenate\n",
    "\n",
    "y_test = np.concatenate((y_test_0, y_test_1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9001, 9600)\n",
      "(10000, 9600)\n",
      "(19001, 9600)\n",
      "(19001,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_0.shape)\n",
    "print(X_test_1.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_0 has 110 batches.\n",
      "X_train_1 has 112 batches.\n"
     ]
    }
   ],
   "source": [
    "n_X_train_0 = len(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_0\"))\n",
    "n_X_train_1 = len(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_1\"))\n",
    "\n",
    "print(f\"X_train_0 has {n_X_train_0} batches.\")\n",
    "print(f\"X_train_1 has {n_X_train_1} batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 38/109 [00:33<01:03,  1.12it/s]\n",
      " 34%|███▍      | 38/111 [00:34<01:05,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# load X_train\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set the amount of batches you wish to consider\n",
    "n = 40\n",
    "\n",
    "k = 1\n",
    "first = os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_0\")[0]\n",
    "X_train_0 = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Train_0/\" + first, allow_pickle=True)\n",
    "\n",
    "for item in tqdm(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_0\")[1:]):\n",
    "    arr = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Train_0/\" + item, allow_pickle=True)\n",
    "    X_train_0 = np.concatenate((X_train_0, arr), axis = 0)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "        break\n",
    "\n",
    "k = 1\n",
    "first = os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_1\")[0]\n",
    "X_train_1 = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Train_1/\" + first, allow_pickle=True)\n",
    "\n",
    "\n",
    "for item in tqdm(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_1\")[1:]):\n",
    "    arr = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Train_1/\" + item, allow_pickle=True)\n",
    "    X_train_1 = np.concatenate((X_train_1, arr), axis = 0)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "        break\n",
    "    \n",
    "X_train = np.concatenate((X_train_0, X_train_1), axis = 0)\n",
    "\n",
    "# load y_test\n",
    "\n",
    "y_train = np.loadtxt(\"labels/seconds_0.2_overlap_0.1/labels_Train.txt\")\n",
    "\n",
    "# split\n",
    "\n",
    "y_train_0 = y_train[y_train == 0]\n",
    "y_train_1 = y_train[y_train == 1]\n",
    "\n",
    "# truncate according to the number of slices selected above\n",
    "\n",
    "y_train_0 = y_train_0[0: X_train_0.shape[0]]\n",
    "y_train_1 = y_train_1[0: X_train_1.shape[0]]\n",
    "\n",
    "# concatenate\n",
    "\n",
    "y_train = np.concatenate((y_train_0, y_train_1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 9600)\n",
      "(39340, 9600)\n",
      "(79340, 9600)\n",
      "(79340,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_0.shape)\n",
    "print(X_train_1.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val_0 has 28 batches.\n",
      "X_val_1 has 27 batches.\n"
     ]
    }
   ],
   "source": [
    "n_X_val_0 = len(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Validation_0\"))\n",
    "n_X_val_1 = len(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Validation_1\"))\n",
    "\n",
    "print(f\"X_val_0 has {n_X_val_0} batches.\")\n",
    "print(f\"X_val_1 has {n_X_val_1} batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X_val\n",
    "\n",
    "# set the amount of batches you wish to consider\n",
    "n = 7\n",
    "\n",
    "k = 1\n",
    "first = os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Validation_0\")[0]\n",
    "X_val_0 = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Validation_0/\" + first, allow_pickle=True)\n",
    "\n",
    "for item in os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Validation_0\")[1:]:\n",
    "    arr = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Validation_0/\" + item, allow_pickle=True)\n",
    "    X_val_0 = np.concatenate((X_val_0, arr), axis = 0)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "        break\n",
    "\n",
    "k = 1\n",
    "first = os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Validation_1\")[0]\n",
    "X_val_1 = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Validation_1/\" + first, allow_pickle=True)\n",
    "\n",
    "for item in os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Validation_1\")[1:]:\n",
    "    arr = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Validation_1/\" + item, allow_pickle=True)\n",
    "    X_val_1 = np.concatenate((X_val_1, arr), axis = 0)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "        break\n",
    "\n",
    "X_val = np.concatenate((X_val_0, X_val_1), axis = 0)\n",
    "\n",
    "# load y_test\n",
    "\n",
    "y_val = np.loadtxt(\"labels/seconds_0.2_overlap_0.1/labels_Validation.txt\")\n",
    "\n",
    "# split\n",
    "\n",
    "y_val_0 = y_val[y_val == 0]\n",
    "y_val_1 = y_val[y_val == 1]\n",
    "\n",
    "# truncate according to the number of slices selected above\n",
    "\n",
    "y_val_0 = y_val_0[0: X_val_0.shape[0]]\n",
    "y_val_1 = y_val_1[0: X_val_1.shape[0]]\n",
    "\n",
    "# concatenate\n",
    "\n",
    "y_val = np.concatenate((y_val_0, y_val_1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79340, 9600, 1)\n",
      "(14000, 9600, 1)\n",
      "(19001, 9600, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((-1, 9600, 1))\n",
    "X_val = X_val.reshape((-1, 9600, 1))\n",
    "X_test = X_test.reshape((-1, 9600, 1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40000.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0., 39340.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWRElEQVR4nO3dbYyd5Z3f8e8vNkncJhAeBuR6nJoGt41BxVmmrtW0FRuvisNWNZFActrG1sqSU0qqrLRVF/KiyaqyhFUlXtEWVk5AGLobsEi2uClsi8zSdLWOvcOWYAyhTAOFiS08CSwhW0Fr8++Lc410PBzPnHn2w/cj3Tr3+d/Xdc51ydb8zv1wzp2qQpKkDyz2ACRJZwYDQZIEGAiSpMZAkCQBBoIkqVm62AOYqcsuu6xWrVq12MOQpLPK008//dOqGui17awNhFWrVjE8PLzYw5Cks0qS/326bR4ykiQBBoIkqTEQJEmAgSBJagwESRJgIEiSmr4DIcmSJP8jyffa80uSPJHkpfZ4cVfbO5KMJHkxyQ1d9euSHG7b7kqSVv9Qkodb/WCSVXM3RUlSP6azh/Bl4IWu57cD+6tqNbC/PSfJGmAzcDWwEbg7yZLW5x5gO7C6LRtbfRvwZlVdBewCds5oNpKkGesrEJIMAr8KfKurvAnY09b3ADd11R+qqner6mVgBFiXZDlwYVUdqM5NGB6Y0Gf8tR4BNozvPUiSFka/31T+beBfAh/tql1RVccAqupYkstbfQXwg652o632/9r6xPp4n9faa51I8hZwKfDT7kEk2U5nD4OPf/zjfQ79/Vbd/p9n3He2XrnzVxftvSVpMlPuIST5B8Dxqnq6z9fs9cm+JqlP1ufUQtXuqhqqqqGBgZ4/xSFJmqF+9hA+DfzDJDcCHwYuTPIfgNeTLG97B8uB4639KLCyq/8gcLTVB3vUu/uMJlkKXAS8McM5SZJmYMpAqKo7gDsAklwP/Iuq+idJ/g2wFbizPT7auuwDfi/JN4C/ROfk8aGqOpnk7STrgYPAFuDfdvXZChwAbgaeLG/2LOkMdi4eep7Nr53eCexNsg14FbgFoKqOJNkLPA+cAG6rqpOtz63A/cAy4PG2ANwLPJhkhM6eweZZjEuSNAPTCoSqegp4qq3/DNhwmnY7gB096sPANT3q79ACRZK0OPymsiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1UwZCkg8nOZTkh0mOJPmtVv9akp8keaYtN3b1uSPJSJIXk9zQVb8uyeG27a4kafUPJXm41Q8mWTX3U5UkTaafPYR3gc9U1bXAWmBjuy8ywK6qWtuWxwCSrKFzC8yrgY3A3UmWtPb3ANvp3Gd5ddsOsA14s6quAnYBO2c/NUnSdEwZCNXxi/b0grbUJF02AQ9V1btV9TIwAqxLshy4sKoOVFUBDwA3dfXZ09YfATaM7z1IkhZGX+cQkixJ8gxwHHiiqg62TV9K8myS+5Jc3GorgNe6uo+22oq2PrF+Sp+qOgG8BVw6g/lIkmaor0CoqpNVtRYYpPNp/xo6h38+Qecw0jHg6615r0/2NUl9sj6nSLI9yXCS4bGxsX6GLknq07SuMqqqPwOeAjZW1estKN4Dvgmsa81GgZVd3QaBo60+2KN+Sp8kS4GLgDd6vP/uqhqqqqGBgYHpDF2SNIV+rjIaSPKxtr4M+BXgR+2cwLjPAc+19X3A5nbl0JV0Th4fqqpjwNtJ1rfzA1uAR7v6bG3rNwNPtvMMkqQFsrSPNsuBPe1KoQ8Ae6vqe0keTLKWzqGdV4AvAlTVkSR7geeBE8BtVXWyvdatwP3AMuDxtgDcCzyYZITOnsHmOZibJGkapgyEqnoW+FSP+hcm6bMD2NGjPgxc06P+DnDLVGORJM0fv6ksSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkC+run8oeTHErywyRHkvxWq1+S5IkkL7XHi7v63JFkJMmLSW7oql+X5HDbdle7tzLt/ssPt/rBJKvmfqqSpMn0s4fwLvCZqroWWAtsTLIeuB3YX1Wrgf3tOUnW0Lkn8tXARuDudj9mgHuA7cDqtmxs9W3Am1V1FbAL2DkHc5MkTcOUgVAdv2hPL2hLAZuAPa2+B7iprW8CHqqqd6vqZWAEWJdkOXBhVR2oqgIemNBn/LUeATaM7z1IkhZGX+cQkixJ8gxwHHiiqg4CV1TVMYD2eHlrvgJ4rav7aKutaOsT66f0qaoTwFvApT3GsT3JcJLhsbGx/mYoSepLX4FQVSerai0wSOfT/jWTNO/1yb4mqU/WZ+I4dlfVUFUNDQwMTDVsSdI0TOsqo6r6M+ApOsf+X2+HgWiPx1uzUWBlV7dB4GirD/aon9InyVLgIuCN6YxNkjQ7/VxlNJDkY219GfArwI+AfcDW1mwr8Ghb3wdsblcOXUnn5PGhdljp7STr2/mBLRP6jL/WzcCT7TyDJGmBLO2jzXJgT7tS6APA3qr6XpIDwN4k24BXgVsAqupIkr3A88AJ4LaqOtle61bgfmAZ8HhbAO4FHkwyQmfPYPNcTE6S1L8pA6GqngU+1aP+M2DDafrsAHb0qA8D7zv/UFXv0AJFkrQ4/KayJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJ6O+eyiuT/GGSF5IcSfLlVv9akp8keaYtN3b1uSPJSJIXk9zQVb8uyeG27a52b2Xa/ZcfbvWDSVbN/VQlSZPpZw/hBPAbVfVJYD1wW5I1bduuqlrblscA2rbNwNXARuDudj9mgHuA7cDqtmxs9W3Am1V1FbAL2Dn7qUmSpmPKQKiqY1X1p239beAFYMUkXTYBD1XVu1X1MjACrEuyHLiwqg5UVQEPADd19dnT1h8BNozvPUiSFsa0ziG0QzmfAg620peSPJvkviQXt9oK4LWubqOttqKtT6yf0qeqTgBvAZf2eP/tSYaTDI+NjU1n6JKkKfQdCEk+AnwH+PWq+jmdwz+fANYCx4Cvjzft0b0mqU/W59RC1e6qGqqqoYGBgX6HLknqQ1+BkOQCOmHwu1X1XYCqer2qTlbVe8A3gXWt+Siwsqv7IHC01Qd71E/pk2QpcBHwxkwmJEmamX6uMgpwL/BCVX2jq768q9nngOfa+j5gc7ty6Eo6J48PVdUx4O0k69trbgEe7eqzta3fDDzZzjNIkhbI0j7afBr4AnA4yTOt9hXg80nW0jm08wrwRYCqOpJkL/A8nSuUbquqk63frcD9wDLg8bZAJ3AeTDJCZ89g8+ymJUmarikDoar+iN7H+B+bpM8OYEeP+jBwTY/6O8AtU41FkjR//KayJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJ6O+eyiuT/GGSF5IcSfLlVr8kyRNJXmqPF3f1uSPJSJIXk9zQVb8uyeG27a52b2Xa/ZcfbvWDSVbN/VQlSZPpZw/hBPAbVfVJYD1wW5I1wO3A/qpaDexvz2nbNgNXAxuBu5Msaa91D7AdWN2Wja2+DXizqq4CdgE752BukqRpmDIQqupYVf1pW38beAFYAWwC9rRme4Cb2vom4KGqereqXgZGgHVJlgMXVtWBqirggQl9xl/rEWDD+N6DJGlhTOscQjuU8yngIHBFVR2DTmgAl7dmK4DXurqNttqKtj6xfkqfqjoBvAVc2uP9tycZTjI8NjY2naFLkqbQdyAk+QjwHeDXq+rnkzXtUatJ6pP1ObVQtbuqhqpqaGBgYKohS5Kmoa9ASHIBnTD43ar6biu/3g4D0R6Pt/oosLKr+yBwtNUHe9RP6ZNkKXAR8MZ0JyNJmrl+rjIKcC/wQlV9o2vTPmBrW98KPNpV39yuHLqSzsnjQ+2w0ttJ1rfX3DKhz/hr3Qw82c4zSJIWyNI+2nwa+AJwOMkzrfYV4E5gb5JtwKvALQBVdSTJXuB5Olco3VZVJ1u/W4H7gWXA422BTuA8mGSEzp7B5lnOS5I0TVMGQlX9Eb2P8QNsOE2fHcCOHvVh4Joe9XdogSJJWhx+U1mSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgT0d0/l+5IcT/JcV+1rSX6S5Jm23Ni17Y4kI0leTHJDV/26JIfbtrvafZVp915+uNUPJlk1t1OUJPWjnz2E+4GNPeq7qmptWx4DSLKGzv2Qr2597k6ypLW/B9gOrG7L+GtuA96sqquAXcDOGc5FkjQLUwZCVX2fzo3v+7EJeKiq3q2ql4ERYF2S5cCFVXWgqgp4ALipq8+etv4IsGF870GStHBmcw7hS0mebYeULm61FcBrXW1GW21FW59YP6VPVZ0A3gIu7fWGSbYnGU4yPDY2NouhS5Immmkg3AN8AlgLHAO+3uq9PtnXJPXJ+ry/WLW7qoaqamhgYGB6I5YkTWpGgVBVr1fVyap6D/gmsK5tGgVWdjUdBI62+mCP+il9kiwFLqL/Q1SSpDkyo0Bo5wTGfQ4YvwJpH7C5XTl0JZ2Tx4eq6hjwdpL17fzAFuDRrj5b2/rNwJPtPIMkaQEtnapBkm8D1wOXJRkFvgpcn2QtnUM7rwBfBKiqI0n2As8DJ4Dbqupke6lb6VyxtAx4vC0A9wIPJhmhs2eweS4mJkmanikDoao+36N87yTtdwA7etSHgWt61N8BbplqHJKk+eU3lSVJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSUAfgZDkviTHkzzXVbskyRNJXmqPF3dtuyPJSJIXk9zQVb8uyeG27a52b2Xa/ZcfbvWDSVbN7RQlSf3oZw/hfmDjhNrtwP6qWg3sb89JsobOPZGvbn3uTrKk9bkH2A6sbsv4a24D3qyqq4BdwM6ZTkaSNHNTBkJVfR94Y0J5E7Cnre8BbuqqP1RV71bVy8AIsC7JcuDCqjpQVQU8MKHP+Gs9AmwY33uQJC2cmZ5DuKKqjgG0x8tbfQXwWle70VZb0dYn1k/pU1UngLeAS3u9aZLtSYaTDI+Njc1w6JKkXub6pHKvT/Y1SX2yPu8vVu2uqqGqGhoYGJjhECVJvcw0EF5vh4Foj8dbfRRY2dVuEDja6oM96qf0SbIUuIj3H6KSJM2zmQbCPmBrW98KPNpV39yuHLqSzsnjQ+2w0ttJ1rfzA1sm9Bl/rZuBJ9t5BknSAlo6VYMk3wauBy5LMgp8FbgT2JtkG/AqcAtAVR1Jshd4HjgB3FZVJ9tL3UrniqVlwONtAbgXeDDJCJ09g81zMjNJ0rRMGQhV9fnTbNpwmvY7gB096sPANT3q79ACRZK0ePymsiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCZhlICR5JcnhJM8kGW61S5I8keSl9nhxV/s7kowkeTHJDV3169rrjCS5q913WZK0gOZiD+GXq2ptVQ2157cD+6tqNbC/PSfJGjr3S74a2AjcnWRJ63MPsB1Y3ZaNczAuSdI0zMcho03Anra+B7ipq/5QVb1bVS8DI8C6JMuBC6vqQFUV8EBXH0nSApltIBTwX5M8nWR7q11RVccA2uPlrb4CeK2r72irrWjrE+vvk2R7kuEkw2NjY7McuiSp29JZ9v90VR1NcjnwRJIfTdK213mBmqT+/mLVbmA3wNDQUM82kqSZmdUeQlUdbY/Hgd8H1gGvt8NAtMfjrfkosLKr+yBwtNUHe9QlSQtoxoGQ5C8m+ej4OvD3geeAfcDW1mwr8Ghb3wdsTvKhJFfSOXl8qB1WejvJ+nZ10ZauPpKkBTKbQ0ZXAL/frhBdCvxeVf1Bkj8B9ibZBrwK3AJQVUeS7AWeB04At1XVyfZatwL3A8uAx9siSVpAMw6EqvoxcG2P+s+ADafpswPY0aM+DFwz07FIkmbPbypLkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJKAMygQkmxM8mKSkSS3L/Z4JOl8c0YEQpIlwL8HPgusAT6fZM3ijkqSzi9nRCAA64CRqvpxVf1f4CFg0yKPSZLOK0sXewDNCuC1ruejwN+a2CjJdmB7e/qLJC/O8P0uA346w76zkp2L8a7AIs55ETnn88N5N+fsnNWc//LpNpwpgZAetXpfoWo3sHvWb5YMV9XQbF/nbOKczw/O+fwwX3M+Uw4ZjQIru54PAkcXaSySdF46UwLhT4DVSa5M8kFgM7BvkcckSeeVM+KQUVWdSPIl4L8AS4D7qurIPL7lrA87nYWc8/nBOZ8f5mXOqXrfoXpJ0nnoTDlkJElaZAaCJAk4xwNhqp/DSMddbfuzSX5pMcY5l/qY8z9uc302yR8nuXYxxjmX+v3ZkyR/M8nJJDcv5PjmQz9zTnJ9kmeSHEny3xZ6jHOpj//XFyX5T0l+2Ob7a4sxzrmU5L4kx5M8d5rtc//3q6rOyYXOyen/BfwV4IPAD4E1E9rcCDxO53sQ64GDiz3uBZjz3wYubuufPR/m3NXuSeAx4ObFHvcC/Dt/DHge+Hh7fvlij3ue5/sVYGdbHwDeAD642GOf5bz/HvBLwHOn2T7nf7/O5T2Efn4OYxPwQHX8APhYkuULPdA5NOWcq+qPq+rN9vQHdL7zcTbr92dP/jnwHeD4Qg5unvQz538EfLeqXgWoqrN53v3Mt4CPJgnwETqBcGJhhzm3qur7dOZxOnP+9+tcDoReP4exYgZtzibTnc82Op8wzmZTzjnJCuBzwO8s4LjmUz//zn8VuDjJU0meTrJlwUY39/qZ778DPknnC62HgS9X1XsLM7xFM+d/v86I7yHMk35+DqOvn8w4i/Q9nyS/TCcQ/s68jmj+9TPn3wZ+s6pOdj5AnvX6mfNS4DpgA7AMOJDkB1X1P+d7cPOgn/neADwDfAb4BPBEkv9eVT+f78Etojn/+3UuB0I/P4dxrv1kRl/zSfI3gG8Bn62qny3Q2OZLP3MeAh5qYXAZcGOSE1X1HxdmiHOu3//bP62qPwf+PMn3gWuBszEQ+pnvrwF3Vufg+kiSl4G/DhxamCEuijn/+3UuHzLq5+cw9gFb2tn69cBbVXVsoQc6h6acc5KPA98FvnCWflqcaMo5V9WVVbWqqlYBjwD/7CwOA+jv//ajwN9NsjTJX6Dz68EvLPA450o/832Vzt4QSa4A/hrw4wUd5cKb879f5+weQp3m5zCS/NO2/XfoXHFyIzAC/B86nzLOWn3O+V8BlwJ3t0/MJ+os/qXIPud8TulnzlX1QpI/AJ4F3gO+VVU9L1880/X5b/yvgfuTHKZzKOU3q+qs/knsJN8GrgcuSzIKfBW4AObv75c/XSFJAs7tQ0aSpGkwECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpOb/A79+M8cbiaTjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(20, 100,\n",
    "                        strides=4,\n",
    "                        activation=\"relu\",\n",
    "                        input_shape=(9600, 1)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = np.loadtxt(\"data/for_prediction/Olaf_Schubert/seconds_0.2_overlap_0/Olaf_Schubert_1/data.txt\")\n",
    "test_audio_2 = np.loadtxt(\"data/for_prediction/Andrew_Ng/seconds_0.2_overlap_0/Andrew_Ng_3/data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_3 = np.loadtxt(\"data/for_prediction/Recording/seconds_0.2_overlap_0/Recording_1/data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_3 = test_audio_3.reshape((-1, 128, width, 1))\n",
    "test_audio_3 = test_audio_3.astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64322917])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_3 = model.predict(\n",
    "    test_audio_3)\n",
    "mask_3 = (predictions_3 > 0.1)\n",
    "sum(mask_3)/len(mask_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = test_audio.reshape((-1, 128, width, 1))\n",
    "test_audio_2 = test_audio_2.reshape((-1, 128, width, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = test_audio.astype(\"float32\")/255.0\n",
    "test_audio_2 = test_audio.astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    test_audio)\n",
    "predictions_2 = model.predict(\n",
    "    test_audio_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_2 = (predictions_2 > 0.5)\n",
    "mask = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.900000000000002\n",
      "44.5\n",
      "62.2\n",
      "65.0\n",
      "68.7\n",
      "129.0\n",
      "142.70000000000002\n",
      "146.8\n",
      "147.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d28862ea3e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(5)\n",
    "for i, b in enumerate(mask):\n",
    "    if b:\n",
    "        print(i*0.2)\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (predictions > 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mask)[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-30-663f0626662c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-663f0626662c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    np.arange(5181)[mask.reshape(-1)]/The 5\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "np.arange(5181)[mask.reshape(-1)]/The 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((preds > 0.1) & (preds < 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5181, 128, 9, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222024, 128, 9, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X_train\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set the amount of batches you wish to consider\n",
    "n = 40\n",
    "\n",
    "k = 1\n",
    "first = os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_0\")[0]\n",
    "X_train_0 = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Train_0/\" + first, allow_pickle=True)\n",
    "df = pd.DataFrame(X_train_0.tolist()).fillna(0)\n",
    "X_train_0 = df.to_numpy().astype(\"int\")\n",
    "np.save(\"data_mp3/seconds_0.2_overlap_0.1/Train_0/\" + first, X_train_0)\n",
    "\n",
    "for item in tqdm(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_0\")[1:]):\n",
    "    arr = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Train_0/\" + item, allow_pickle=True)\n",
    "    df = pd.DataFrame(arr.tolist()).fillna(0)\n",
    "    arr = df.to_numpy().astype(\"int\")\n",
    "    np.save(\"data_mp3/seconds_0.2_overlap_0.1/Train_0/\" + item, arr)\n",
    "    X_train_0 = np.concatenate((X_train_0, arr), axis = 0)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "        break\n",
    "\n",
    "k = 1\n",
    "first = os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_1\")[0]\n",
    "X_train_1 = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Train_1/\" + first, allow_pickle=True)\n",
    "df = pd.DataFrame(X_train_1.tolist()).fillna(0)\n",
    "X_train_1 = df.to_numpy().astype(\"int\")\n",
    "np.save(\"data_mp3/seconds_0.2_overlap_0.1/Train_1/\" + first, X_train_1)\n",
    "\n",
    "for item in tqdm(os.listdir(\"data_mp3/seconds_0.2_overlap_0.1/Train_1\")[1:]):\n",
    "    arr = np.load(\"data_mp3/seconds_0.2_overlap_0.1/Train_1/\" + item, allow_pickle=True)\n",
    "    df = pd.DataFrame(arr.tolist()).fillna(0)\n",
    "    arr = df.to_numpy().astype(\"int\")\n",
    "    np.save(\"data_mp3/seconds_0.2_overlap_0.1/Train_1/\" + item, arr)\n",
    "    X_train_1 = np.concatenate((X_train_1, arr), axis = 0)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "        break\n",
    "    \n",
    "X_train = np.concatenate((X_train_0, X_train_1), axis = 0)\n",
    "\n",
    "# load y_test\n",
    "\n",
    "y_train = np.loadtxt(\"labels/seconds_0.2_overlap_0.1/labels_Train.txt\")\n",
    "\n",
    "# split\n",
    "\n",
    "y_train_0 = y_train[y_train == 0]\n",
    "y_train_1 = y_train[y_train == 1]\n",
    "\n",
    "# truncate according to the number of slices selected above\n",
    "\n",
    "y_train_0 = y_train_0[0: X_train_0.shape[0]]\n",
    "y_train_1 = y_train_1[0: X_train_1.shape[0]]\n",
    "\n",
    "# concatenate\n",
    "\n",
    "y_train = np.concatenate((y_train_0, y_train_1), axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
